{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9feb4c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (1.21.6)\n",
      "Requirement already satisfied: nltk in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from click->nltk) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from importlib-metadata->click->nltk) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from importlib-metadata->click->nltk) (4.7.1)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: bs4 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.4.1)\n",
      "Requirement already satisfied: deep_translator in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from deep_translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from deep_translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2024.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: pymystem3 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from pymystem3) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests->pymystem3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests->pymystem3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests->pymystem3) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages (from requests->pymystem3) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install nltk\n",
    "!pip install pymorphy2\n",
    "!pip install bs4\n",
    "!pip install deep_translator\n",
    "!pip install scikit-learn\n",
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8bd0b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vsevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vsevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vsevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vsevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from bs4 import BeautifulSoup\n",
    "from deep_translator import GoogleTranslator\n",
    "from pymystem3 import Mystem\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "punctuation = list(punctuation)\n",
    "\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922711b-8ebf-4573-b6e2-aab0cdb93272",
   "metadata": {},
   "source": [
    "# Импорт входных данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "330842d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   failed_resumes       29 non-null     object\n",
      " 1   confirmed_resumes    29 non-null     object\n",
      " 2   vacancy.uuid         29 non-null     object\n",
      " 3   vacancy.name         29 non-null     object\n",
      " 4   vacancy.keywords     0 non-null      object\n",
      " 5   vacancy.description  29 non-null     object\n",
      " 6   vacancy.comment      4 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "with open('case_2_data_for_members.json', 'r', encoding='utf-8') as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(data_json)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db9985-6b20-4350-bce3-a24bd2ebd311",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15dae17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевод текста на русский язык\n",
    "def translate_text(text):\n",
    "    translator = GoogleTranslator(source='auto', target='ru')\n",
    "    try:\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        \n",
    "        return text\n",
    "\n",
    "# Разбиение на чанки для перевода\n",
    "def translate_chunked(text, chunk_size=4999):\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    translated_chunks = [translate_text(chunk) for chunk in chunks]\n",
    "    \n",
    "    return ''.join(translated_chunks)\n",
    "\n",
    "# Нормализация текста\n",
    "def normalize_text(s):\n",
    "    # Лемматизация \n",
    "    lemms = m.lemmatize(s)\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + nltk.corpus.stopwords.words('russian')\n",
    "    lemms = [token for token in lemms if token not in stopwords \\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    # удаляем стоп-слова из нашего текста\n",
    "    words_without_stop = [i for i in lemms if i not in stopwords]\n",
    "    # Вывод значения в строке\n",
    "    total = ''\n",
    "    for el in lemms:\n",
    "      total+=el\n",
    "      total+=' '\n",
    "        \n",
    "    return total\n",
    "\n",
    "# Очистка от html\n",
    "def del_html (s):\n",
    "    soup = BeautifulSoup(s, 'html.parser')\n",
    "    soup.get_text()\n",
    "    for data in soup(['style', 'script']):\n",
    "      data.decompose()\n",
    "    script_out = ' '.join(soup.stripped_strings)\n",
    "    \n",
    "    return script_out\n",
    "\n",
    "# Получение текстового представления вакансии\n",
    "def concat_vacancy(vacancy: dict) -> str: \n",
    "    string = ' '.join(\n",
    "        [\n",
    "            vacancy['vacancy']['name'],\n",
    "            str(vacancy['vacancy']['keywords']),\n",
    "            vacancy['vacancy']['description'],\n",
    "            vacancy['vacancy']['comment']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return string\n",
    "\n",
    "# Получение текстового представления резюме\n",
    "def concat_resume(resume: dict) -> tuple:\n",
    "    resume_concated = tuple(\n",
    "        [\n",
    "            resume['key_skills'],\n",
    "            ' '.join([desc['description'] for desc in resume['experienceItem']])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return resume_concated\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    text = text.replace('&nbsp', \" \")\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e35ef718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_key_words (s: str) -> str:\n",
    "    url = \"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "      \"model\": \"GigaChat\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f'Выпиши ключевые компетенции и технологический стек из следующей вакансии: {s}' \n",
    "        }\n",
    "      ],\n",
    "      \"temperature\": 1,\n",
    "      \"top_p\": 0.1,\n",
    "      \"n\": 1,\n",
    "      \"stream\": False,\n",
    "      \"max_tokens\": 512,\n",
    "      \"repetition_penalty\": 1,\n",
    "      \"update_interval\": 0\n",
    "    })\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json',\n",
    "      'Accept': 'application/json',\n",
    "      'Authorization': 'Bearer eyJjdHkiOiJqd3QiLCJlbmMiOiJBMjU2Q0JDLUhTNTEyIiwiYWxnIjoiUlNBLU9BRVAtMjU2In0.oqEaHFqkfNn1hnUzjJ-9JCYHpH_RXFS9oNCCdA0WKwLkkR0huvBbTKE5UjdK5HRiv4zdMiPg0SPSBXFCUEl63A-d5o9kgsdiZz_qWS8sVWqTLTVZBnYmgut_eYbZoMMK1fj1Ugv8ELRhmhb8vk4Gxe6FnhIYpcBd-d6bhwS9KJIcE2xQjDgc7nG6GqY4rPIrn3x_MyqgZCOQq-2U6P77Zy01fcAewuWR0yLV8FEm-sGxtZQXUupaC3Cyy3EESMVvloxK_hg66u_USAzE3SCQUbLj0KsN9qqjUMauWJ4QkLXOQZfTPTTdYRATDETaJg1_LfjUhBGjMgBiCDEiJTgCGw.OdUiYqad1NUtnCos5DgLyw.eqYwHnMRhH3uGYYGQgbVjdyf0bA8HujWXd-m4lFXeInTcyduzxYDjAJIPvIerc1SZHP0lJNuxJFeeGglhOCcuGM47PV8bzb6rLxmjBvGHkodCEBoArCVRNVVQggphwGtg_qO3qDQbYOM6nXyJOBP9dmnCCGJpv1k3KeF1dJ0KAAfICSme-a1qngbG0f0U47kU8RVwKrz1--WQseuJ0kvqyOoTlLjGifH5VDMNiPq26NBDWJ-yZ5cPatDibwXdXPTsYgkbBwL0ZJ9R1i1XjwVy9hiykl3ZRO1aTov1kejgEr3xnZ-jMNf-knFHfyjxs3d9sDARRHHZZOeUlh6Lv89ZGCxIQnqUKc-31DooAOKaKXGirDJj5CIsOb_oi2OuebBkXE7ekgcyJ1YckH4ir1Zor5B_O---te7fCvVniK5dxALjO69t_1ZFOW5KmE8QmNiPY9ibGWPBfwHASEnWBcFjWoxryjmxbzpBRR2PF192DoA73s-wdgPVpnlM80nFmxmR3DsNtM6AMtZisnMF7GR3LVDxfWZknUVGHbWYMBN-ZMHYMY4lhqIe7r8whwyzCvHSi32YJnsFIfBj7k4gn4gqaJbQwELtpta1jHykHyVaPpuAp95swxzUh9HsYMO9hfXOg7fbKYTjl-h3O7IvEjxhuspYNa3nWrDTCtMaX4ZYJXPMoaqIL27bF9nvXxUcVMYXtzSgn8xtfMJB-2qN4bYW63Dnz6ASWJPWiteMg3WTJo.9DE8cGdC5FPzKXj1-23uTvw9aLixdKEp6VeD4qS6tGM'}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload, verify=False)\n",
    "\n",
    "    # status_code == 200 - код успешного запроса\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        # Очистить от спец символов и букв в случае плохого ответа модели; -> int\n",
    "        return content\n",
    "    else:\n",
    "        # Если запрос не успешен, вывести сообщение об ошибке\n",
    "        print(\"Ошибка при выполнении запроса:\", response.status_code)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f19b29b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при выполнении запроса: 401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1107: InsecureRequestWarning: Unverified HTTPS request is being made to host 'gigachat.devices.sberbank.ru'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Java разработчик команда Инвестиции None  Описание Мы расширяем команды и ищем разработчиков для развития нескольких сервисов:   Инвестиции. Мы — лидер среди брокеров по количеству активных клиентов. Делаем инвестиции удобными, технологичными и понятными;   Бизнес. Меняем подход к ведению бухгалтерии, обмену документами между организациями и работе с архивами — переводим все и вся в цифру;   Страхование. Развиваем платформу прямых продаж. Наша цель — предсказуемый, удобный процесс для бизнеса и клиента; Платежные технологии и процессинг. Занимаемся разработкой и поддержкой платежного шлюза банка. Задачи шлюза — определять тип платежей, наполнять их данными из других систем банка и проверять разрешенность операций. У нас много интересных и разнообразных задач, опытная команда и отличные возможности для роста. Откликайтесь на вакансию, чтобы узнать о проектах и выбрать подходящий для вас. Требования Опыт разработки на Java от 3 лет Опыт коммерческой разработки на Java 11+ или Kotlin Опыт коммерческой разработки с любым из фреймворков: Spring Boot, Quarkus, Micronaut или Vert.x Опыт коммерческой разработки с одним из контейнеризаторов: Kubernetes, Docker или OpenShift Опыт коммерческой разработки с одним из брокеров: Kafka, Rabbit MQ или Active MQ Опыт коммерческой разработки с Postgress, MySQL или Oracle будет плюсом Опыт работы с системой контроля версий Мы предлагаем Работу в офисе или удаленно — по договоренности Возможность работы в аккредитованной ИТ-компании Платформу обучения и развития «  Апгрейд». Курсы, тренинги, вебинары и базы знаний. Поддержку менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Бесплатный фитнес-зал или компенсацию затрат на спортивные занятия 3 дополнительных дня отпуска в год Уникальную well-being-программу, направленную на физическое и ментальное благополучие сотрудников Достойную зарплату — обсудим ее на собеседовании  450 на руки'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vacancy_key_words (concat_vacancy(data_json[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896198a0-c3d2-4080-b7e4-f1cfee169f69",
   "metadata": {},
   "source": [
    "## Импорт и обработка спарсенных данных с HH.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6942c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hh = pd.concat([pd.read_csv('vacations_design.csv'), pd.read_csv('vacations_dev.csv'),  pd.read_csv('vacations_devops.csv'), pd.read_csv('vacations_ml.csv'),  pd.read_csv('vacations_prdm.csv'), pd.read_csv('vacations_prjm.csv'), pd.read_csv('vacations_qa.csv'), pd.read_csv('vacations.csv')], axis=0)\n",
    "df_hh['description'] = df_hh['description'].map(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c33737e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3401"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (df_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "821ebd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_train = normalize_text (\" <ENDMESSAGE> \".join(df_hh['description']))\n",
    "texts_lemmatized = text_for_train.split(' ENDMESSAGE ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476dd7d3-3323-49e9-96e3-903d39e6bb65",
   "metadata": {},
   "source": [
    "## Обучение TF-idf векторайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90abc17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.2, max_features=3000, min_df=0.005)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df = 0.2, min_df = 0.005, max_features = 3000)\n",
    "vectorizer.fit(texts_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7ab2021-b9eb-4c23-8fe9-7ef9829f0b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b796276e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf-idf.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(vectorizer, 'tf-idf.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54163bbf-8136-4924-b973-58fbbd34d569",
   "metadata": {},
   "source": [
    "## Работа через TF-idf векторайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a4327b0-f3e3-4df1-82a2-aa4374bb4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_cos_sim(vac: str,\n",
    "                 resume: str,\n",
    "                 vectorizer):\n",
    "    \n",
    "    vac = normalize_text(remove_html_tags(translate_chunked(vac)))\n",
    "    vac_vect = vectorizer.transform([vac])\n",
    "    resume = normalize_text(remove_html_tags(translate_chunked(' '.join(resume))))\n",
    "    resume_vect = vectorizer.transform([resume])\n",
    "    cosin_sim = cosine_similarity(vac_vect[0], resume_vect[0])\n",
    "    \n",
    "    return cosin_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15c6b140-887c-47ee-943e-4e2ee4d876ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1348864]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_cos_sim (concat_vacancy(data_json[0]), concat_resume(data_json[0]['failed_resumes'][0]), vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55beadd4-9655-4632-bb2a-736b4240161e",
   "metadata": {},
   "source": [
    "## Пайплайн для CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a5ffa62-e61f-4686-9d00-dcda451bec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def cv_cos_sim(vac: str, \n",
    "               resume: str): \n",
    "    \n",
    "    vac = normalize_text(remove_html_tags(vac))\n",
    "    cv_vectorizer = CountVectorizer(binary = True).fit([vac])\n",
    "    vac_vect = cv_vectorizer.transform([vac])\n",
    "    resume = normalize_text(remove_html_tags(translate_chunked(' '.join(resume))))\n",
    "    resume_vect = cv_vectorizer.transform([resume])\n",
    "    cosin_sim = cosine_similarity(vac_vect[0], resume_vect[0])\n",
    "    \n",
    "    return cosin_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b302b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vsevo\\pycharmprojects\\talentmatch\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1107: InsecureRequestWarning: Unverified HTTPS request is being made to host 'gigachat.devices.sberbank.ru'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при выполнении запроса: 401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20044593]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_cos_sim (get_vacancy_key_words(concat_vacancy(data_json[1])), concat_resume(data_json[5]['failed_resumes'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3781ee8",
   "metadata": {},
   "source": [
    "## Итоговая оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f019e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cos_sim ():\n",
    "    \n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a02f01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def agregated_cos_sim (array_text, array_tf_idf, array_cv):\n",
    "    \n",
    "    array_text = normalize ([array_text], norm=\"l1\")[0]\n",
    "    array_tf_idf = normalize ([array_tf_idf], norm=\"l1\")[0]\n",
    "    array_cv = normalize ([array_cv], norm=\"l1\")[0]\n",
    "    \n",
    "    array_itog = [(i1+i2+i3)/3 for i1, i2, i3 in zip(array_text, array_tf_idf, array_cv)]\n",
    "    return array_itog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94af237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   resumes              1 non-null      object\n",
      " 1   vacancy.uuid         1 non-null      object\n",
      " 2   vacancy.name         1 non-null      object\n",
      " 3   vacancy.keywords     1 non-null      object\n",
      " 4   vacancy.description  1 non-null      object\n",
      " 5   vacancy.comment      0 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "with open('case_2_reference_without_resume_sorted.json', 'r', encoding='utf-8') as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(data_json)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a187623a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['resumes'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
